{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "using\n",
    "CSV,\n",
    "DataFrames,\n",
    "DecisionTree,\n",
    "Plots,\n",
    "Random,\n",
    "Statistics,\n",
    "StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, Plot{Plots.GRBackend() n=1}, 0.99)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function threshold_costs(actual, preds)\n",
    "    \"costs of all different thresholds\"\n",
    "    costs = []\n",
    "    best_threshold = 0\n",
    "    for i in range(0, 1, step=0.01)\n",
    "        threshold = i\n",
    "        cost = cost_function(actual, [if i > threshold 1 else 0 end for i in preds])\n",
    "        push!(costs, cost)\n",
    "        if cost == minimum(costs)\n",
    "            best_threshold = i\n",
    "        end\n",
    "    end\n",
    "    p1 = plot(costs, ylim=(0, maximum(costs)), label=\"\")\n",
    "    return minimum(costs), p1, best_threshold\n",
    "end\n",
    "threshold_costs([1,1,1,1,0,1,1,0,0,0,0], [1,1,1,1,1,1,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing functions\n",
    "function fill_missing_mean(df::DataFrame)\n",
    "    X = df\n",
    "    tmp = dropmissing(X, disallowmissing=true)\n",
    "    is_numeric = [typeof(i[1]) <: Number for i in eachcol(tmp)]\n",
    "    counter = 1\n",
    "    for col in names(X)\n",
    "        if is_numeric[counter]\n",
    "            X[!, Symbol(col)] = recode(X[!, Symbol(col)], missing => mean(skipmissing(X[!, Symbol(col)])))\n",
    "        end\n",
    "        counter += 1\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "function class_to_bool(df::DataFrame)\n",
    "    X = df\n",
    "    logic(x) = if x == \"neg\" 0 else 1 end\n",
    "    X[!, :class] = logic.(X.class)\n",
    "    return X\n",
    "end\n",
    "\n",
    "function min_max_scale(df::DataFrame)\n",
    "    X = df\n",
    "    tmp = dropmissing(X, disallowmissing=true)\n",
    "    is_numeric = [typeof(i[1]) <: Number for i in eachcol(tmp)]\n",
    "    counter = 1\n",
    "    for col in names(X)\n",
    "        if is_numeric[counter]\n",
    "            X[!, Symbol(col)] = (X[!, Symbol(col)] .- minimum(X[!, Symbol(col)])) / (maximum(X[!, Symbol(col)]) - minimum(X[!, Symbol(col)]))\n",
    "        end\n",
    "        counter += 1\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "function process_dataset(X::DataFrame)\n",
    "    X |> fill_missing_mean |> class_to_bool |> min_max_scale\n",
    "end\n",
    "\n",
    "# ML functions\n",
    "function train_test_split(X::DataFrame; target_col::String, seed=0, train_share=0.8)\n",
    "    function partitionTrainTest(data, at=0.8, seed=0)\n",
    "        if seed != 0\n",
    "            Random.seed!(seed)\n",
    "        end\n",
    "        n = nrow(data)\n",
    "        idx = shuffle(1:n)\n",
    "        train_idx = view(idx, 1:floor(Int, at*n))\n",
    "        test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "        data[train_idx,:], data[test_idx,:]\n",
    "    end\n",
    "\n",
    "    train,test = partitionTrainTest(X, train_share, seed)\n",
    "    X_train = select(train, Not(Symbol(target_col)))\n",
    "    y_train = train[!, Symbol(target_col)]\n",
    "    X_test = select(test, Not(Symbol(target_col)))\n",
    "    y_test = test[!, Symbol(target_col)]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "end\n",
    "\n",
    "function cost_function(actuals, predictions)\n",
    "    cost(actual, prediction) = if actual == 1 && prediction == 0 500 elseif actual == 0 && prediction == 1 10 else 0 end\n",
    "    return sum(cost.(actuals, predictions))\n",
    "end\n",
    "\n",
    "function threshold_costs(actual, preds)\n",
    "    \"costs of all different thresholds\"\n",
    "    costs = []\n",
    "    best_threshold = 0\n",
    "    for i in range(0, 1, step=0.01)\n",
    "        threshold = i\n",
    "        cost = cost_function(actual, [if i > threshold 1 else 0 end for i in preds])\n",
    "        push!(costs, cost)\n",
    "        if cost == minimum(costs)\n",
    "            best_threshold = i\n",
    "        end\n",
    "    end\n",
    "    p1 = plot(costs, ylim=(0, maximum(costs)), label=\"\")\n",
    "    return minimum(costs), p1, best_threshold\n",
    "end\n",
    "    \n",
    "function cross_fold(train::DataFrame, test::DataFrame, model, n=10)\n",
    "    validation_perf = []\n",
    "    best_thresholds = []\n",
    "    for i in 1:n\n",
    "        println(\"Fold $i/$n\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, target_col=\"class\")\n",
    "        DecisionTree.fit!(model, convert(Matrix, X_train), convert(Array, y_train))\n",
    "        preds = DecisionTree.predict(dt, convert(Matrix, X_test))\n",
    "        lowest, p1, best_threshold = threshold_costs(y_test, preds)\n",
    "        push!(validation_perf, lowest)\n",
    "        push!(best_thresholds, best_threshold)\n",
    "    end\n",
    "    # training on all data\n",
    "    X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(train, target_col=\"class\", train_share=1.0)\n",
    "    DecisionTree.fit!(model, convert(Matrix, X_train_final), convert(Array, y_train_final))\n",
    "    \n",
    "    # test set\n",
    "    test_X_train, test_X_test, test_y_train, test_y_test = train_test_split(test, target_col=\"class\", train_share=0)\n",
    "    preds = DecisionTree.predict(dt, convert(Matrix, test_X_test))\n",
    "    test_perf = cost_function(test_y_test, [if i > mean(best_thresholds) 1 else 0 end for i in preds])\n",
    "        \n",
    "    return mean(validation_perf), test_perf\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = CSV.File(\"data/aps_failure_training_set.csv\"; missingstring=\"na\") |> DataFrame! |> process_dataset\n",
    "test = CSV.File(\"data/aps_failure_test_set.csv\"; missingstring=\"na\") |> DataFrame! |> process_dataset\n",
    "# historical performance of algorithms\n",
    "perf = CSV.file(\"data/performance.csv\") |> DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "performance = []\n",
    "max_depth = [10, 50, 100, -1]\n",
    "min_samples_split = [2, 5, 20, 50]\n",
    "min_samples_leaf = [1, 5, 20, 50]\n",
    "min_purity_increase = [0.0, 0.001, 0.01]\n",
    "for md in max_depth\n",
    "    for mss in min_samples_split\n",
    "        for msl in min_samples_leaf\n",
    "            for mpi in min_purity_increase\n",
    "                params = \"decision tree, max_depth:$md, min_samples_split:$mss, min_samples_leaf:$msl, min_purity_increase:$mpi\"\n",
    "                println(params)\n",
    "                dt = DecisionTreeRegressor(\n",
    "                    max_depth = md,\n",
    "                    min_samples_split = mss,\n",
    "                    min_samples_leaf = msl,\n",
    "                    min_purity_increase = mpi\n",
    "                )\n",
    "                validation_results, test_results = cross_fold(training, test, dt, 1)\n",
    "                push!(performance, (\n",
    "                    params,\n",
    "                    validation_results,\n",
    "                    test_results,\n",
    "                    \"all features\"\n",
    "                ))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "tmp_perf = DataFrame(performance)\n",
    "names!(tmp_perf, [:desc, :val_score, :test_score, :notes])\n",
    "perf = [perf; tmp_perf]\n",
    "CSV.write(\"data/performance.csv\", perf)\n",
    "best_score = minimum([i[2] for i in performance])\n",
    "best_params = [i[1] for i in performance if i[2] == best_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "performance = []\n",
    "n_subfeatures = round(0.5*length(names(training)), digits=0)#-1\n",
    "n_trees = [100]#[20, 50, 100]\n",
    "partial_sampling = [0.7]#[0.7, 1]\n",
    "max_depth = [-1]#[-1, 5]\n",
    "min_samples_leaf = [5]#[5, 10]\n",
    "min_samples_split = [10]#[2, 10]\n",
    "min_purity_increase = 0.0\n",
    "\n",
    "for nt in n_trees\n",
    "    for ps in partial_sampling\n",
    "        for md in max_depth\n",
    "            for msl in min_samples_leaf\n",
    "                for mss in min_samples_split\n",
    "                    params = \"random forest, n_subfeatures:$n_subfeatures, n_trees:$nt, partial_sampling:$ps, max_depth:$md, min_samples_leaf:$msl, min_samples_split:$mss, min_purity_increase:$min_purity_increase\"\n",
    "                    println(params)\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(training, target_col=\"class\", train_share=0.8)\n",
    "                    rf = build_forest(y_train, convert(Matrix, X_train),\n",
    "                                         n_subfeatures,\n",
    "                                         nt,\n",
    "                                         ps,\n",
    "                                         md,\n",
    "                                         msl,\n",
    "                                         mss,\n",
    "                                         min_purity_increase\n",
    "                         )\n",
    "                    preds = apply_forest(rf, convert(Matrix, X_test))\n",
    "                    validation_results, p1, best_threshold = threshold_costs(y_test, preds)\n",
    "                    \n",
    "                    test_X_train, test_X_test, test_y_train, test_y_test = train_test_split(test, target_col=\"class\", train_share=0)\n",
    "                    preds = apply_forest(rf, convert(Matrix, test_X_test))\n",
    "                    test_results = cost_function(test_y_test, [if i > best_threshold 1 else 0 end for i in preds])\n",
    "                    \n",
    "                    params *= \", best_threshold:$best_threshold\"\n",
    "                    push!(performance, (\n",
    "                     params,\n",
    "                     validation_results,\n",
    "                     test_results,\n",
    "                     \"all features\"\n",
    "                    ))\n",
    "                 end\n",
    "             end\n",
    "         end\n",
    "     end\n",
    "end\n",
    "tmp_perf = DataFrame(performance)\n",
    "names!(tmp_perf, [:desc, :val_score, :test_score, :notes])\n",
    "perf = [perf; tmp_perf]\n",
    "CSV.write(\"data/performance.csv\", perf)\n",
    "best_score = minimum([i[2] for i in performance])\n",
    "best_params = [i[1] for i in performance if i[2] == best_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6×4 DataFrame\n",
      "│ Row │ │     │ ├─────┼\n",
      "│ 1   │ │ 2   │ │ 3   │ │ 4   │ │ 5   │ │ 6   │ \n",
      "\n",
      "│ Row │ desc                                                                                                                                                                     │\n",
      "│     │ \u001b[90mUnion{Missing, String}\u001b[39m                                                                                                                                                   │\n",
      "├─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ 1   │ decision tree, max_depth:-1, min_samples_split:50, min_samples_leaf:20, min_purity_increase:0.001                                                                        │\n",
      "│ 2   │ decision tree, max_depth:-1, min_samples_split:50, min_samples_leaf:20, min_purity_increase:0.01                                                                         │\n",
      "│ 3   │ decision tree, max_depth:-1, min_samples_split:50, min_samples_leaf:50, min_purity_increase:0.0                                                                          │\n",
      "│ 4   │ decision tree, max_depth:-1, min_samples_split:50, min_samples_leaf:50, min_purity_increase:0.001                                                                        │\n",
      "│ 5   │ decision tree, max_depth:-1, min_samples_split:50, min_samples_leaf:50, min_purity_increase:0.01                                                                         │\n",
      "│ 6   │ random forest, n_subfeatures:86.0, n_trees:50, partial_sampling:0.7, max_depth:-1, min_samples_leaf:5, min_samples_split:10, min_purity_increase:0.0, best_threshold:0.1 │\n",
      "\n",
      "│ Row │ val_score │ test_score │ notes        │\n",
      "│     │ \u001b[90mFloat64⍰\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mString⍰\u001b[39m      │\n",
      "├─────┼───────────┼────────────┼──────────────┤\n",
      "│ 1   │ 35570.0   │ 78020      │ all features │\n",
      "│ 2   │ 102500.0  │ 187500     │ all features │\n",
      "│ 3   │ 11380.0   │ 19640      │ all features │\n",
      "│ 4   │ 28760.0   │ 73470      │ all features │\n",
      "│ 5   │ 91000.0   │ 187500     │ all features │\n",
      "│ 6   │ 7610.0    │ 14540      │ all features │"
     ]
    }
   ],
   "source": [
    "showall(perf[end-5:end, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
